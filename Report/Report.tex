\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry} % Add geometry package here
\geometry{margin=1.5in} % Set the margin size here
\usepackage{listings}
\usepackage{fancyhdr}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{pgfplots}
\usepackage{biblatex}

\addbibresource{sources.bib}

\pgfplotsset{compat=1.16}

\graphicspath{ {./images/} }

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    pdfpagemode=FullScreen,
}

\definecolor{code-gray}{RGB}{220, 220, 220}

\pagestyle{fancy}
\fancyhf{}
\fancyfoot[LE,RO]{\thepage}

\lstset{
  basicstyle=\ttfamily,
  columns=fullflexible,
  frame=single,
  breaklines=true,
  showstringspaces=false,
  backgroundcolor=\color{code-gray}
}

\renewcommand{\headrulewidth}{1pt}
\renewcommand{\footrulewidth}{1pt}


\begin{document}

\begin{titlepage}
  \begin{center}
      \vspace*{1cm}

      \LARGE
      \textbf{Diffusion Models in Depth: From a Theoretical and a Practical Perspective}

      \vspace{1.5cm}

      \Large
      \textbf{Gregory Sedykh}
      \vspace{0.8cm}

      \normalsize
      June 28th 2024

      \vfill

      \includegraphics[width=0.4\textwidth]{images/informatics_en.png} \\

      Bachelor thesis for the degree of Bachelor of Science in Computer Science \\
      Supervised by Prof. St√©phane Marchand-Maillet     

      \vspace{0.8cm}
    
           
           
  \end{center}
\end{titlepage}


\newpage
\section*{Abstract}

\newpage
\tableofcontents

\pagenumbering{arabic}

%% ----------------------- Content goes here ----------------------- %%

\newpage
\section{Introduction}

Diffusion models have gained widespread popularity since 2020, as models such as DALL-E, Stable Diffusion and Midjourney have proven to be capable of generating high-quality images given a text prompt. Furthermore, OpenAI's recent announcement of Sora has shown that diffusion models have now also become highly capable of generating minute long high-definition videos from a text prompt. \cite{videoworldsimulators2024}
\\\\
These models date back to 2015, where the idea of a diffusion model appeared, based on diffusion processes used in thermodynamics. \cite{sohldickstein2015deep} \\
Denoising Diffusion Probabilistic Models (DDPMs) were a development of the original diffusion probabilistic model introduced in 2015. \cite{ho2020denoising} \\
Subsequently, OpenAI improved upon the original DDPMs which did not have ideal log likelihoods \cite{ho2020denoising} while also using less forward passes and therefore speeding up the sampling process. \cite{nichol2021improved} \\
The most recent progress done by OpenAI has allowed their diffusion models to obtain better metrics and better sample quality than Generative Adversarial Networks (GANs) which were previously considered the state-of-the-art in image generation. \cite{dhariwal2021diffusion}
\\\\
The fairly recent apparition of diffusion models means not only that there is still a lot to be discovered about them, but also that progress is being made rapidly. \\
The theory behind diffusion models was mainly founded when Ho et al. \cite{ho2020denoising} introduced their DDPMs in 2020, but many improvements have been made upon their work since then. \\ 
To understand what these models are and how they work, it is crucial to understand how DDPMs were developed, what choices were made when developing them and why these choices were made, as well as why changes were made to the original model and how they were made.
\\\\
This report aims to provide an overview of the theory behind diffusion models, as well as a practical guide on how to implement a simple diffusion model using PyTorch, in order to compare what the theory shows us and what the practical implementation gives us.

\newpage
\section{Denoising Diffusion Probabilistic Models}

A \textbf{diffusion model} is a generative model that consists of two Markov chains, one forward and one reverse. \\
Given an input (e.g. an image), the forward process will destroy the image by gradually adding Gaussian noise at each step of the process. \cite{ho2020denoising} \\
The reverse process' objective is to "reverse" the forward process, starting from the noisy image and step-by-step, estimating the noise that was added to the image at each step and removing it until the first step is reached, where we should obtain the original image. \cite{ho2020denoising} \\

\subsection{Forward Process}

The forward process is a Markov process that starts from the original image $x_0$ and adds Gaussian noise during $T$ steps, where each step $i \in [1, T]$ has a size $\beta_i \in \{ \beta_1, ..., \beta_T \}$, which results in a more noisy image $x_i$. \cite{ho2020denoising}
\\\\
Formally, we obtain:
\begin{gather}
  q(x_{1}, ... x_{T} | x_0) = \prod_{t = 1}^T{q(x_t | x_{t - 1})} \label{eq:1} \\
  q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t}x_{t-1}, \beta_t I) \label{eq:2}
\end{gather}
\\\\
Equation \ref{eq:2} gives us a single step forward: given the previous image $x_{t-1}$, we add noise from a Gaussian distribution with mean $\sqrt{1 - \beta_t}x_{t-1}$ and variance $\beta_t I$ to obtain the next image $x_t$. \\
Equation \ref{eq:1} gives us the full forward process from the original image $x_0$ to the final image $x_T$.
\\\\
It is important to note that as $T \rightarrow \infty$ and with a correct choice of $\beta_t$,  $x_T$ will become a sample of an isotropic Gaussian distribution ($\mathcal{N}(0, I)$). \cite{nichol2021improved} \cite{sohldickstein2015deep}. \\
This is important for the reverse process, as it will allow us to take a sample $x_T \sim \mathcal{N}(0, I)$ and reverse the forward process to obtain the original image $x_0$ (however this cannot be done so simply, as seen in section 3) \cite{nichol2021improved}.

\subsection{Reverse Process}

\subsection{Comparaison with other diffusion models}

\newpage
\section{Improvements upon DDPMs}

\newpage
\section{Results}

\newpage
\section{Conclusion}

%% ----------------------------------------------------------------- %%

\newpage
\printbibliography

\end{document}
